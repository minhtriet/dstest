{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This requires running tr_q1 first\n",
    "\n",
    "The order of the notebook is as follow, \n",
    "- Split train val test class\n",
    "- Define a baseline\n",
    "- Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import os\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "seed = 42\n",
    "\n",
    "MAX_LENGTH = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I take the headtext and firsts characters of each paragraph and concatenatem together, such that each row in the dataset are representend by `MAX_LENGTH` characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'TRDataChallenge2023.zip'\n",
    "extract_file_path = 'TRDataChallenge2023'\n",
    "df = pd.read_json(os.path.join(extract_file_path, f\"{extract_file_path}.txt\"), lines=True).head(10)   # todo\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = pd.Series(np.array(mlb.fit_transform(df[\"postures\"].values), dtype=\"float\").tolist(), name=\"label_ids\")\n",
    "df = pd.concat([df, labels], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documentId</th>\n",
       "      <th>postures</th>\n",
       "      <th>sections</th>\n",
       "      <th>label_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ib4e590e0a55f11e8a5d58a2c8dcb28b5</td>\n",
       "      <td>[On Appeal]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Plaintiff Dw...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ib06ab4d056a011e98c7a8e995225dbf9</td>\n",
       "      <td>[Appellate Review, Sentencing or Penalty Phase...</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['After pleadi...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iaa3e3390b93111e9ba33b03ae9101fb2</td>\n",
       "      <td>[Motion to Compel Arbitration, On Appeal]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Frederick Gr...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I0d4dffc381b711e280719c3f0e80bdd0</td>\n",
       "      <td>[On Appeal, Review of Administrative Decision]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Appeal from ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I82c7ef10d6d111e8aec5b23c3317c9c0</td>\n",
       "      <td>[On Appeal]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Order, Supre...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          documentId  \\\n",
       "0  Ib4e590e0a55f11e8a5d58a2c8dcb28b5   \n",
       "1  Ib06ab4d056a011e98c7a8e995225dbf9   \n",
       "2  Iaa3e3390b93111e9ba33b03ae9101fb2   \n",
       "3  I0d4dffc381b711e280719c3f0e80bdd0   \n",
       "4  I82c7ef10d6d111e8aec5b23c3317c9c0   \n",
       "\n",
       "                                            postures  \\\n",
       "0                                        [On Appeal]   \n",
       "1  [Appellate Review, Sentencing or Penalty Phase...   \n",
       "2          [Motion to Compel Arbitration, On Appeal]   \n",
       "3     [On Appeal, Review of Administrative Decision]   \n",
       "4                                        [On Appeal]   \n",
       "\n",
       "                                            sections  \\\n",
       "0  [{'headtext': '', 'paragraphs': ['Plaintiff Dw...   \n",
       "1  [{'headtext': '', 'paragraphs': ['After pleadi...   \n",
       "2  [{'headtext': '', 'paragraphs': ['Frederick Gr...   \n",
       "3  [{'headtext': '', 'paragraphs': ['Appeal from ...   \n",
       "4  [{'headtext': '', 'paragraphs': ['Order, Supre...   \n",
       "\n",
       "                        label_ids  \n",
       "0  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 1.0]  \n",
       "2  [0.0, 1.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "3  [0.0, 0.0, 0.0, 1.0, 1.0, 0.0]  \n",
       "4  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally we `fit_transform` in the train set and `transform` on the test set. However here I `fit_transform` in the whole dataset to cover all of the labels, because some of them only have one instance (See first notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_strings(max_len, sections):\n",
    "    \"\"\"\n",
    "    Remove the \\\\u and clean up texts\n",
    "    \"\"\"\n",
    "    cleaned_sections = []\n",
    "    chars_per_section = max_len // len(sections)\n",
    "    for section in sections:            \n",
    "        cleaned_text = \"\"\n",
    "        headtext = [section['headtext'].encode(\"ascii\", \"ignore\").decode().strip()]\n",
    "        cleaned_paragraph = [paragraph.encode(\"ascii\", \"ignore\").decode().strip() for paragraph in section['paragraphs']]\n",
    "        cleaned_text += \". \".join(headtext + cleaned_paragraph)        \n",
    "        \n",
    "        if (len(cleaned_text) < chars_per_section):\n",
    "            cleaned_sections.append(cleaned_text[:len(cleaned_text)])\n",
    "        else:\n",
    "            last_space_index = cleaned_text[:chars_per_section].rfind(' ')\n",
    "            cleaned_sections.append(cleaned_text[:last_space_index])  # last element that is a space\n",
    "\n",
    "    cleaned_sections = '. '.join(cleaned_sections)\n",
    "\n",
    "    return cleaned_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_clean_up_strings():\n",
    "    # Test the function with a basic scenario\n",
    "    max_len = 50\n",
    "    sections = [\n",
    "        {\n",
    "            'headtext': \"Sample Headline\",\n",
    "            'paragraphs': [\"This is the first paragraph.\"]\n",
    "        },\n",
    "        {\n",
    "            'headtext': \"Sample Headline\",\n",
    "            'paragraphs': [\"Second paragraph.\"]\n",
    "        }\n",
    "    ]\n",
    "    cleaned_sections = clean_up_strings(max_len, sections)    \n",
    "    expected_result = 'Sample Headline. This is. Sample Headline. Second'    \n",
    "    assert cleaned_sections == expected_result\n",
    "\n",
    "test_clean_up_strings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_text\"] = df.sections.map(lambda x: clean_up_strings(MAX_LENGTH, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documentId</th>\n",
       "      <th>postures</th>\n",
       "      <th>sections</th>\n",
       "      <th>label_ids</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ib4e590e0a55f11e8a5d58a2c8dcb28b5</td>\n",
       "      <td>[On Appeal]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Plaintiff Dw...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>. Plaintiff Dwight Watson (Husband) appeals fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ib06ab4d056a011e98c7a8e995225dbf9</td>\n",
       "      <td>[Appellate Review, Sentencing or Penalty Phase...</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['After pleadi...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>. After pleading guilty, William Jerome Howard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iaa3e3390b93111e9ba33b03ae9101fb2</td>\n",
       "      <td>[Motion to Compel Arbitration, On Appeal]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Frederick Gr...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>. Frederick Greene, the plaintiff below, deriv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I0d4dffc381b711e280719c3f0e80bdd0</td>\n",
       "      <td>[On Appeal, Review of Administrative Decision]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Appeal from ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>. Appeal from an amended judgment of the Supre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I82c7ef10d6d111e8aec5b23c3317c9c0</td>\n",
       "      <td>[On Appeal]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Order, Supre...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>. Order, Supreme Court, New York County (Arthu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iafe9e30074ba11e88be5ff0f408d813f</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'headtext': 'OPINION &amp; ORDER', 'paragraphs':...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>OPINION &amp; ORDER. The Grievance Committee for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Icfcdb0e00bed11ea83e6f815c7cdf150</td>\n",
       "      <td>[Appellate Review, Sentencing or Penalty Phase...</td>\n",
       "      <td>[{'headtext': 'OPINION', 'paragraphs': ['In 20...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>OPINION. In 2017, a jury convicted Jose Carlos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I0c356d10cfce11e79fcefd9d4766cbba</td>\n",
       "      <td>[Motion to Dismiss]</td>\n",
       "      <td>[{'headtext': 'ORDER OF DISMISSAL', 'paragraph...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>ORDER OF DISMISSAL. BACKGROUND. Plaintiff U.S....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I53552890fb1e11e790b3a4cf54beb9bd</td>\n",
       "      <td>[On Appeal]</td>\n",
       "      <td>[{'headtext': 'SUMMARY ORDER', 'paragraphs': [...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>SUMMARY ORDER. Petitioner-appellant Chauncey M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I916de920dad811e7929ecf6e705a87cd</td>\n",
       "      <td>[On Appeal]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': [' Plaintiffs ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>. Plaintiffs appeal a judgment dismissing a. F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          documentId  \\\n",
       "0  Ib4e590e0a55f11e8a5d58a2c8dcb28b5   \n",
       "1  Ib06ab4d056a011e98c7a8e995225dbf9   \n",
       "2  Iaa3e3390b93111e9ba33b03ae9101fb2   \n",
       "3  I0d4dffc381b711e280719c3f0e80bdd0   \n",
       "4  I82c7ef10d6d111e8aec5b23c3317c9c0   \n",
       "5  Iafe9e30074ba11e88be5ff0f408d813f   \n",
       "6  Icfcdb0e00bed11ea83e6f815c7cdf150   \n",
       "7  I0c356d10cfce11e79fcefd9d4766cbba   \n",
       "8  I53552890fb1e11e790b3a4cf54beb9bd   \n",
       "9  I916de920dad811e7929ecf6e705a87cd   \n",
       "\n",
       "                                            postures  \\\n",
       "0                                        [On Appeal]   \n",
       "1  [Appellate Review, Sentencing or Penalty Phase...   \n",
       "2          [Motion to Compel Arbitration, On Appeal]   \n",
       "3     [On Appeal, Review of Administrative Decision]   \n",
       "4                                        [On Appeal]   \n",
       "5                                                 []   \n",
       "6  [Appellate Review, Sentencing or Penalty Phase...   \n",
       "7                                [Motion to Dismiss]   \n",
       "8                                        [On Appeal]   \n",
       "9                                        [On Appeal]   \n",
       "\n",
       "                                            sections  \\\n",
       "0  [{'headtext': '', 'paragraphs': ['Plaintiff Dw...   \n",
       "1  [{'headtext': '', 'paragraphs': ['After pleadi...   \n",
       "2  [{'headtext': '', 'paragraphs': ['Frederick Gr...   \n",
       "3  [{'headtext': '', 'paragraphs': ['Appeal from ...   \n",
       "4  [{'headtext': '', 'paragraphs': ['Order, Supre...   \n",
       "5  [{'headtext': 'OPINION & ORDER', 'paragraphs':...   \n",
       "6  [{'headtext': 'OPINION', 'paragraphs': ['In 20...   \n",
       "7  [{'headtext': 'ORDER OF DISMISSAL', 'paragraph...   \n",
       "8  [{'headtext': 'SUMMARY ORDER', 'paragraphs': [...   \n",
       "9  [{'headtext': '', 'paragraphs': [' Plaintiffs ...   \n",
       "\n",
       "                        label_ids  \\\n",
       "0  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "2  [0.0, 1.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "3  [0.0, 0.0, 0.0, 1.0, 1.0, 0.0]   \n",
       "4  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "6  [1.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "7  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "8  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "9  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  . Plaintiff Dwight Watson (Husband) appeals fr...  \n",
       "1  . After pleading guilty, William Jerome Howard...  \n",
       "2  . Frederick Greene, the plaintiff below, deriv...  \n",
       "3  . Appeal from an amended judgment of the Supre...  \n",
       "4  . Order, Supreme Court, New York County (Arthu...  \n",
       "5  OPINION & ORDER. The Grievance Committee for t...  \n",
       "6  OPINION. In 2017, a jury convicted Jose Carlos...  \n",
       "7  ORDER OF DISMISSAL. BACKGROUND. Plaintiff U.S....  \n",
       "8  SUMMARY ORDER. Petitioner-appellant Chauncey M...  \n",
       "9  . Plaintiffs appeal a judgment dismissing a. F...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"documentId\", \"cleaned_text\"]], df[\"label_ids\"], test_size=0.2, random_state=seed)\n",
    "y_train = np.stack(y_train, axis=0)\n",
    "y_test = np.stack(y_test, axis=0)\n",
    "y_pred = [['Appellate Review']] * len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[2, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[2, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[1, 0],\n",
       "        [1, 0]],\n",
       "\n",
       "       [[2, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[1, 0],\n",
       "        [1, 0]]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(y_true=y_test, y_pred=mlb.transform(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ext.minh.triet.chau\\code\\dstest\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2222222222222222"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true=y_test, y_pred=mlb.transform(y_pred), average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at poltextlab/xlm-roberta-large-english-legal-cap and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([22, 1024]) in the checkpoint and torch.Size([6, 1024]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([22]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-large')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('poltextlab/xlm-roberta-large-english-legal-cap',\n",
    "                                                           num_labels= len(mlb.classes_),\n",
    "                                                           problem_type=\"multi_label_classification\",\n",
    "                                                           ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    encoding = tokenizer(examples[\"cleaned_text\"], padding=\"max_length\", truncation=True, max_length=512)    \n",
    "    \n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = Dataset.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10/10 [00:00<00:00, 625.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = train_dataset.map(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 22%|██▏       | 2/9 [00:25<01:30, 12.89s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=3,\n",
    "    output_dir='./output', \n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n"
     ]
    }
   ],
   "source": [
    "results = trainer.predict(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ext.minh.triet.chau\\code\\dstest\\tr_q2.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ext.minh.triet.chau/code/dstest/tr_q2.ipynb#Y304sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39margmax(results\u001b[39m.\u001b[39mpredictions)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "np.argmax(results.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.3941845 , -1.6327689 , -1.4802446 ,  0.1399697 , -1.4017375 ,\n",
       "         -1.8464881 ],\n",
       "        [-0.3776071 , -1.4899278 , -1.7351217 , -0.65194833, -1.6428034 ,\n",
       "         -0.24245712]], dtype=float32),\n",
       " array([[0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results.predictions, results.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "We noticed from 1st question\n",
    "- Most common class: Appellate Review\n",
    "- Most common number of labels: 1\n",
    "\n",
    "Therefore, the baseline would be to predict everything with \"Appellate Review\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The representability of the data\n",
    "  - Is the distribution of the labels represent the real world\n",
    "\n",
    "- We note that the many classes have only one example, for example\n",
    "  ```\n",
    "  Application for Bankruptcy Trustee Fees\n",
    "  Declinatory Exception of Improper Venue\n",
    "  Declinatory Exception of Insufficiency of Service of Process\n",
    "  Declinatory Exception of Lack of Personal Jurisdiction\n",
    "  Dilatory Exception of Unauthorized Use of Summary Proceeding\n",
    "  Joinder\n",
    "  Motion Authorizing and Approving Payment of Certain Prepetition Obligations\n",
    "  Motion for Abandonment of Property\n",
    "  Motion for Adequate Protection\n",
    "  Motion for Appointment of an Expert\n",
    "  Motion for Contempt for Violating Discharge Injunction or Order\n",
    "  Objection to Disclosure Statement\n",
    "  Peremptory Exception of Nonjoinder of a Party\n",
    "  Petition for Legal Separation\n",
    "  Petition for Special Action\n",
    "  Petition to Prevent Relocation\n",
    "  ```\n",
    "  - It makes sense to collect more examples for these problem, just bear in mind to keep the label distribution of the training data in line with real world \n",
    "  - There are 224 classes in this problem, and some classes are related to each other, for example `'Declinatory Exception of Improper Venue', 'Declinatory Exception of Insufficiency of Service of Process', 'Declinatory Exception of Lack of Personal Jurisdiction'` are all Declinatory posture. \n",
    "    - Intuitively it makes sense to split those labels into a separate problem. However a more end-to-end approach the label relations between them, as explored [in this paper](https://openaccess.thecvf.com/content_cvpr_2016/papers/Hu_Learning_Structured_Inference_CVPR_2016_paper.pdf) and [this library](http://scikit.ml/labelrelations.html)\n",
    "    - This could alleviate the problems that many classes have only one examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
