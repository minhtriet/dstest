{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This requires running tr_q1 first\n",
    "\n",
    "The order of the notebook is as follow, \n",
    "- Split train val test class\n",
    "- Define a baseline\n",
    "- Use off-the-shelf-model\n",
    "- Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split a train val test class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'TRDataChallenge2023.zip'\n",
    "extract_file_path = 'TRDataChallenge2023'\n",
    "df = pd.read_json(os.path.join(extract_file_path, f\"{extract_file_path}.txt\"), lines=True)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = pd.Series(list(mlb.fit_transform(df[\"postures\"].values)), name=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documentId</th>\n",
       "      <th>postures</th>\n",
       "      <th>sections</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ib4e590e0a55f11e8a5d58a2c8dcb28b5</td>\n",
       "      <td>[On Appeal]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Plaintiff Dw...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ib06ab4d056a011e98c7a8e995225dbf9</td>\n",
       "      <td>[Appellate Review, Sentencing or Penalty Phase...</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['After pleadi...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iaa3e3390b93111e9ba33b03ae9101fb2</td>\n",
       "      <td>[Motion to Compel Arbitration, On Appeal]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Frederick Gr...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I0d4dffc381b711e280719c3f0e80bdd0</td>\n",
       "      <td>[On Appeal, Review of Administrative Decision]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Appeal from ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I82c7ef10d6d111e8aec5b23c3317c9c0</td>\n",
       "      <td>[On Appeal]</td>\n",
       "      <td>[{'headtext': '', 'paragraphs': ['Order, Supre...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          documentId  \\\n",
       "0  Ib4e590e0a55f11e8a5d58a2c8dcb28b5   \n",
       "1  Ib06ab4d056a011e98c7a8e995225dbf9   \n",
       "2  Iaa3e3390b93111e9ba33b03ae9101fb2   \n",
       "3  I0d4dffc381b711e280719c3f0e80bdd0   \n",
       "4  I82c7ef10d6d111e8aec5b23c3317c9c0   \n",
       "\n",
       "                                            postures  \\\n",
       "0                                        [On Appeal]   \n",
       "1  [Appellate Review, Sentencing or Penalty Phase...   \n",
       "2          [Motion to Compel Arbitration, On Appeal]   \n",
       "3     [On Appeal, Review of Administrative Decision]   \n",
       "4                                        [On Appeal]   \n",
       "\n",
       "                                            sections  \\\n",
       "0  [{'headtext': '', 'paragraphs': ['Plaintiff Dw...   \n",
       "1  [{'headtext': '', 'paragraphs': ['After pleadi...   \n",
       "2  [{'headtext': '', 'paragraphs': ['Frederick Gr...   \n",
       "3  [{'headtext': '', 'paragraphs': ['Appeal from ...   \n",
       "4  [{'headtext': '', 'paragraphs': ['Order, Supre...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally we `fit_transform` in the train set and `transform` on the test set. However here I `fit_transform` in the whole dataset to cover all of the labels, because some of them only have one instance (See first notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"documentId\", \"sections\"]], df[\"labels\"], test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a loss function\n",
    "Multilabel multiclass classification, choose Sigmoid\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "We noticed from 1st question\n",
    "- Most common class: Appellate Review\n",
    "- Most common number of labels: 1\n",
    "\n",
    "Therefore, the baseline would be to predict everything with \"Appellate Review\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [['Appellate Review']] * len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ext.minh.triet.chau\\code\\dstest\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:900: UserWarning: unknown class(es) [' ', 'A', 'R', 'a', 'e', 'i', 'l', 'p', 't', 'v', 'w'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ext.minh.triet.chau\\code\\dstest\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:900: UserWarning: unknown class(es) [' ', 'A', 'R', 'a', 'e', 'i', 'l', 'p', 't', 'v', 'w'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of unknown and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ext.minh.triet.chau\\code\\dstest\\tr_q2.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ext.minh.triet.chau/code/dstest/tr_q2.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m multilabel_confusion_matrix(y_true\u001b[39m=\u001b[39;49my_test, y_pred\u001b[39m=\u001b[39;49mmlb\u001b[39m.\u001b[39;49mtransform(y_pred))\n",
      "File \u001b[1;32mc:\\Users\\ext.minh.triet.chau\\code\\dstest\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ext.minh.triet.chau\\code\\dstest\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:505\u001b[0m, in \u001b[0;36mmultilabel_confusion_matrix\u001b[1;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m    396\u001b[0m     {\n\u001b[0;32m    397\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    406\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, samplewise\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    407\u001b[0m ):\n\u001b[0;32m    408\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute a confusion matrix for each class or sample.\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \n\u001b[0;32m    410\u001b[0m \u001b[39m    .. versionadded:: 0.21\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[39m            [1, 2]]])\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 505\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    506\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    507\u001b[0m         sample_weight \u001b[39m=\u001b[39m column_or_1d(sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\ext.minh.triet.chau\\code\\dstest\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of unknown and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "multilabel_confusion_matrix(y_true=y_test, y_pred=mlb.transform(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use off-the-shelf models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"lexlms/legal-roberta-large\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"lexlms/legal-roberta-large\", problem_type=\"multi_label_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlpaueb/legal-bert-base-uncased\", problem_type=\"multi_label_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question\n",
    "- The representative power of the data\n",
    "  - Is the distribution of the labels represent the real world\n",
    "\n",
    "- We note that the following classes have only one example:\n",
    "  ```\n",
    "  Application for Bankruptcy Trustee Fees\n",
    "  Declinatory Exception of Improper Venue\n",
    "  Declinatory Exception of Insufficiency of Service of Process\n",
    "  Declinatory Exception of Lack of Personal Jurisdiction\n",
    "  Dilatory Exception of Unauthorized Use of Summary Proceeding\n",
    "  Joinder\n",
    "  Motion Authorizing and Approving Payment of Certain Prepetition Obligations\n",
    "  Motion for Abandonment of Property\n",
    "  Motion for Adequate Protection\n",
    "  Motion for Appointment of an Expert\n",
    "  Motion for Contempt for Violating Discharge Injunction or Order\n",
    "  Motion for Genetic Testing\n",
    "  Motion for Leave to File Late or Untimely Notice of Appeal\n",
    "  Motion for Maritime Attachment and Garnishment\n",
    "  Motion for Qualified Domestic Relations Order (QDRO)\n",
    "  Motion for Witness List or Production of Witnesses\n",
    "  Motion to Admonish Jury\n",
    "  Motion to Allow Late Filing of Proof of Claim\n",
    "  Motion to Appoint Chapter 11 Trustee or Examiner\n",
    "  Motion to Appoint Substitute Custodian of Vessel\n",
    "  Motion to Approve Disclosure Statement\n",
    "  Motion to Compel Abandonment\n",
    "  Motion to Deny Class Certification\n",
    "  Motion to Determine Tax Liability\n",
    "  Motion to Enforce Child Custody Decree\n",
    "  Motion to Extend Claims Bar Date\n",
    "  Motion to Increase/Reduce Security\n",
    "  Motion to Reinstate Visitation or Parenting Time\n",
    "  Motion to Remove a Non-Suit\n",
    "  Motion to Sell Property Free and Clear of Interests\n",
    "  Motion to Serve Additional Discovery Requests\n",
    "  Motion to Set Aside Default Judgment\n",
    "  Motion to Surcharge Collateral\n",
    "  Motion to Transfer Guardianship\n",
    "  Motion to Vacate Arbitration Award\n",
    "  Motion to Vacate Attachment\n",
    "  Motion to Vacate Wardship\n",
    "  Motion to Withdraw Reference\n",
    "  Motion to Withdraw an Admission\n",
    "  Objection to Disclosure Statement\n",
    "  Peremptory Exception of Nonjoinder of a Party\n",
    "  Petition for Legal Separation\n",
    "  Petition for Special Action\n",
    "  Petition to Prevent Relocation\n",
    "  ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
